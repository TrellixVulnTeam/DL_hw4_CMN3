{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e212c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966362e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading the dataset & Pre trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f5261b2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchtext.data\n",
    "import torchtext.datasets\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "from RNN import SentimentGRU\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device =\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a2871",
   "metadata": {},
   "source": [
    "load the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8fc32db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training   samples: 8544\n",
      "Number of validation samples: 1101\n",
      "Number of test       samples: 2210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "\n",
    "# torchtext Field objects parse text (e.g. a review) and create a tensor representation\n",
    "\n",
    "# This Field object will be used for tokenizing the movie reviews text\n",
    "review_parser = torchtext.data.Field(\n",
    "    sequential=True, use_vocab=True, lower=True,\n",
    "    init_token='<sos>', eos_token='<eos>', dtype=torch.long,\n",
    "    tokenize='spacy', tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "# This Field object converts the text labels into numeric values (0,1,2)\n",
    "label_parser = torchtext.data.Field(\n",
    "    is_target=True, sequential=False, unk_token=None, use_vocab=True\n",
    ")\n",
    "\n",
    "# Load SST, tokenize the samples and labels\n",
    "# ds_X are Dataset objects which will use the parsers to return tensors\n",
    "ds_train, ds_valid, ds_test = torchtext.datasets.SST.splits(\n",
    "    review_parser, label_parser, root=data_dir\n",
    ")\n",
    "\n",
    "n_train = len(ds_train)\n",
    "print(f'Number of training   samples: {n_train}')\n",
    "print(f'Number of validation samples: {len(ds_valid)}')\n",
    "print(f'Number of test       samples: {len(ds_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fbb1c",
   "metadata": {},
   "source": [
    "As required, we'll use the pre-trained word embeddings of glove 6B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cfd7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary size is 40k, Embedding chosen size in 50\n",
    "vocab, embeddings = [],[]\n",
    "with open('./GloVe/glove.6B.50d.txt','rt',encoding='utf8') as fi:\n",
    "    full_content = fi.read().strip().split('\\n')\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0]\n",
    "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    vocab.append(i_word)\n",
    "    embeddings.append(i_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b6540",
   "metadata": {},
   "source": [
    "add padding and unknown tokens to the embeddings array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5c85fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>' '<unk>' 'the' ',' '.' 'of' 'to' 'and' 'in' 'a']\n"
     ]
    }
   ],
   "source": [
    "# Add the padding and the unknown tokens to the vocab and embeddings arrays\n",
    "\n",
    "vocab = np.array(vocab) \n",
    "embeddings = np.array(embeddings)\n",
    "vocab = np.insert(vocab, 0, '<pad>')\n",
    "vocab = np.insert(vocab, 1, '<unk>')\n",
    "\n",
    "unk_emb = np.mean(embeddings, axis=0, keepdims=True)\n",
    "pad_emb = np.zeros_like(embeddings[0]).reshape(1,-1)\n",
    "\n",
    "\n",
    "embeddings = np.vstack((pad_emb, unk_emb, embeddings))\n",
    "\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3e9bc",
   "metadata": {},
   "source": [
    "## Baseline Model - Sentiment Analysis using RNN - GRU\n",
    "\n",
    "As for the first part in our experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb5ea6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, dataloader, max_epochs=100,\n",
    "          num_batches=400, save_path=None):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    \n",
    "    for epoch_idx in range(max_epochs):\n",
    "        total_loss, num_correct = 0, 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            X, y = batch.text, batch.label\n",
    "\n",
    "            # Forward pass\n",
    "            _, y_pred_log_proba = model(X)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(y_pred_log_proba, y)\n",
    "            loss.backward()\n",
    "\n",
    "            # Weight updates\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            total_loss += loss.item()\n",
    "            y_pred = torch.argmax(y_pred_log_proba, dim=1)\n",
    "            num_correct += torch.sum(y_pred == y).float().item()\n",
    "\n",
    "            if batch_idx == num_batches-1:\n",
    "                break\n",
    "        \n",
    "        curr_train_loss = total_loss /(num_batches)\n",
    "        curr_train_acc = num_correct /(num_batches*BATCH_SIZE)\n",
    "        train_losses.append(curr_train_loss)\n",
    "        train_acc.append(curr_train_acc)\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch #{epoch_idx}, loss={curr_train_loss:.3f}, accuracy={curr_train_acc:.3f}, elapsed={time.time()-start_time:.1f} sec\")\n",
    "        \n",
    "        if save_path:\n",
    "            torch.save(model, save_path)\n",
    "            \n",
    "    return train_losses, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc059d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4eade0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_valid, dl_test = torchtext.data.BucketIterator.splits(\n",
    "    (ds_train, ds_valid, ds_test), batch_size=BATCH_SIZE,\n",
    "    shuffle=True, device=device)\n",
    "review_parser.build_vocab(ds_train)\n",
    "label_parser.build_vocab(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8ce7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SentimentGRU(embeddings, hidden_size=HIDDEN_SIZE,\n",
    "                     num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d04e48a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentGRU(\n",
      "  (embedding_layer): Embedding(400002, 50)\n",
      "  (gru): GRU(50, 256, num_layers=2)\n",
      "  (dense_linear): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./models/sentimentGRU.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0bfbe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dorbi\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9919, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0121, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0792, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0924, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1190, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1356, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0392, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1263, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3da64f3e7aa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_losses, train_accs = train(model, optimizer, loss_fn, dl_train, max_epochs=100,\n\u001b[0m\u001b[0;32m      2\u001b[0m       num_batches=500, save_path = \"./models/sentimentGRU.pt\")\n",
      "\u001b[1;32m<ipython-input-6-dacf1dc4fb2a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, dataloader, max_epochs, num_batches, save_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_log_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# Weight updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_accs = train(model, optimizer, loss_fn, dl_train, max_epochs=100,\n",
    "      num_batches=500, save_path = \"./models/sentimentGRU.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbffdab",
   "metadata": {},
   "source": [
    "And evaluate on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "768c919c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-57c53c1059b7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-60-57c53c1059b7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def test_epoch(model, loss_fn, dataloader)\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def test_epoch(model, loss_fn, dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    num_correct = 0 \n",
    "    num_batches = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            num_batches = batch_idx\n",
    "            X, y = batch.text, batch.label\n",
    "\n",
    "            _, y_test = model(X)\n",
    "            loss = loss_fn(y_test, y)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            test_loss += loss.item()\n",
    "            y_pred = torch.argmax(y_test, dim=1)\n",
    "            num_correct += torch.sum(y_pred == y).float().item()\n",
    "            \n",
    "                 \n",
    "        test_loss = total_loss /(num_batches)\n",
    "        test_acc = num_correct /(num_batches*BATCH_SIZE)\n",
    "\n",
    "    model.train()\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf2f2a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac03da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentSelfAttention(\n",
      "  (embedding_layer): Embedding(400002, 50)\n",
      "  (q_feedforward): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (k_feedforward): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (v_feedforward): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (PositionalEncoding): PositionalEncoding()\n",
      "  (SelfAttention1): MultiheadAttention(\n",
      "    (out_proj): _LinearWithBias(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (dense_linear): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "trainable params: 18003\n"
     ]
    }
   ],
   "source": [
    "from SelfAttention import SentimentSelfAttention\n",
    "\n",
    "model_attention = SentimentSelfAttention(embeddings, num_heads=1).to(device)\n",
    "print(model_attention)\n",
    "\n",
    "print(\"trainable params:\", \n",
    "      sum(p.numel() for p in model_attention.parameters() if p.requires_grad)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf747c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape: torch.Size([49, 32])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dl_train)).text.to(device)\n",
    "print(\"batch shape:\", batch.shape)\n",
    "_ = model_attention(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca426677-7a3f-4db9-bcec-759c2e528582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #1, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #2, loss=0.743, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #3, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #4, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #5, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #6, loss=0.743, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #7, loss=0.743, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #8, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #9, loss=0.743, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #10, loss=0.742, accuracy=0.282, elapsed=0.9 sec\n",
      "Epoch #11, loss=0.742, accuracy=0.282, elapsed=1.0 sec\n",
      "Epoch #12, loss=0.743, accuracy=0.282, elapsed=1.0 sec\n",
      "Epoch #13, loss=0.742, accuracy=0.282, elapsed=1.0 sec\n",
      "Epoch #14, loss=0.742, accuracy=0.282, elapsed=1.0 sec\n",
      "Epoch #15, loss=0.742, accuracy=0.282, elapsed=1.1 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-f7f3ed4838a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(model_attention, optimizer, loss_fn, dl_train, max_epochs=100,\n\u001b[0m\u001b[0;32m      2\u001b[0m           num_batches=400, save_path=None)\n",
      "\u001b[1;32m<ipython-input-55-a54a7c32e121>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, dataloader, max_epochs, num_batches, save_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_log_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs236781-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Study\\DL\\hw4\\project\\SelfAttention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_feedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_embedded_pe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mattention_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelfAttention1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;31m# print(\"attention out shape:\", attention_out.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs236781-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs236781-hw\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs236781-hw\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4012\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_b\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4013\u001b[0m                 \u001b[0m_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4014\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4016\u001b[0m         \u001b[0mq_proj_weight_non_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_proj_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs236781-hw\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model_attention, optimizer, loss_fn, dl_train, max_epochs=100,\n",
    "          num_batches=400, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd34e3a-0771-4631-a09d-80eba584af45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
