{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8322104-e3a5-40f9-a5fe-d172427bfe51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the dataset & Pre trained word embeddings\n",
    "\n",
    "As required, we'll use the pre-trained word embeddings of glove 6B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d35c3c05-abc3-498b-b1e7-d1c601ea5124",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dorbi\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torchtext\\data\\example.py:94: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "C:\\Users\\dorbi\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "C:\\Users\\dorbi\\miniconda3\\envs\\cs236781-hw\\lib\\site-packages\\torchtext\\data\\example.py:94: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 8544\n",
      "Number of test     samples: 2210\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchtext.data\n",
    "import torchtext.datasets\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "\n",
    "# torchtext Field objects parse text (e.g. a review) and create a tensor representation\n",
    "\n",
    "# This Field object will be used for tokenizing the movie reviews text\n",
    "review_parser = torchtext.data.Field(\n",
    "    sequential=True, use_vocab=True, lower=True,\n",
    "    init_token='<sos>', eos_token='<eos>', dtype=torch.long,\n",
    "    tokenize='spacy', tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "# This Field object converts the text labels into numeric values (0,1,2)\n",
    "label_parser = torchtext.data.Field(\n",
    "    is_target=True, sequential=False, unk_token=None, use_vocab=True\n",
    ")\n",
    "\n",
    "# Load SST, tokenize the samples and labels\n",
    "# ds_X are Dataset objects which will use the parsers to return tensors\n",
    "ds_train, ds_valid, ds_test = torchtext.datasets.SST.splits(\n",
    "    review_parser, label_parser, root=data_dir\n",
    ")\n",
    "\n",
    "n_train = len(ds_train)\n",
    "print(f'Number of training samples: {n_train}')\n",
    "print(f'Number of test     samples: {len(ds_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ba368-bcb2-4110-9fb3-ed49d2c97c48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in ([111, 4321, 7000, 0]):\n",
    "    example = ds_train[i]\n",
    "    label = example.label\n",
    "    review = str.join(\" \", example.text)\n",
    "    print(f'sample#{i:04d} [{label:8s}]:\\n > {review}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a8701-de8d-4d86-ae18-d58a8a9f1add",
   "metadata": {},
   "source": [
    "And now lets load the pre-trained word embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e5ed5d79-db48-43a2-89e6-058bf9ea962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample#0111 [positive]:\n",
      " > the film aims to be funny , uplifting and moving , sometimes all at once .\n",
      "\n",
      "sample#4321 [neutral ]:\n",
      " > the most anti - human big studio picture since 3000 miles to graceland .\n",
      "\n",
      "sample#7000 [negative]:\n",
      " > it 's a barely tolerable slog over well - trod ground .\n",
      "\n",
      "sample#0000 [positive]:\n",
      " > the rock is destined to be the 21st century 's new ` ` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean - claud van damme or steven segal .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "#Vocabulary size is 40k, Embedding chosen size in 50\n",
    "vocab, embeddings = [],[]\n",
    "with open('.\\project\\GloVe\\GloVe\\glove.6B\\glove.6B.50d.txt','rt',encoding='utf8') as fi:\n",
    "    full_content = fi.read().strip().split('\\n')\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0]\n",
    "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    vocab.append(i_word)\n",
    "    embeddings.append(i_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c89a6c24-7465-47de-a62d-d0fa9bf1e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>' '<unk>' 'the' ',' '.' 'of' 'to' 'and' 'in' 'a']\n"
     ]
    }
   ],
   "source": [
    "# Add the padding and the unknown tokens to the vocab and embeddings arrays\n",
    "\n",
    "vocab = np.array(vocab) \n",
    "embeddings = np.array(embeddings)\n",
    "vocab = np.insert(vocab, 0, '<pad>')\n",
    "vocab = np.insert(vocab, 1, '<unk>')\n",
    "\n",
    "pad_emb = np.zeros_like(embeddings[0]).reshape(1,-1)\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b61448d6-c2f0-4306-bc5e-07d260a4c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50])\n"
     ]
    }
   ],
   "source": [
    "# Apply Embedding pre trained layer to random input\n",
    "\n",
    "my_embedding_layer = torch.nn.Embedding.from_pretrained(torch.from_numpy(embeddings).float())\n",
    "EMBEDDING_DIM = 50\n",
    "in_p = torch.randint(low=1, high=3, size=(10,))\n",
    "print(my_embedding_layer(in_p).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baae0b50-b8bd-4f9d-b99a-7a5ebc2efb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400002, 50)\n"
     ]
    }
   ],
   "source": [
    "unk_emb = np.mean(embeddings, axis=0, keepdims=True)\n",
    "embeddings = np.vstack((pad_emb, unk_emb, embeddings))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02664b4-3c2c-4a17-a804-1af0a1efaddc",
   "metadata": {},
   "source": [
    "## Baseline Model - Sentiment Analysis using RNN - LSTM\n",
    "\n",
    "As for the first part in our experiment\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
